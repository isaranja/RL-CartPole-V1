{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CartPole-V1_DQN_Keras.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/isaranja/RL-CartPole-V1/blob/master/CartPole_V1_DQN_Keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wtg8Ht6tPyHC",
        "colab_type": "text"
      },
      "source": [
        "# Deep Q-Learning with Keras for CartPole-V1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJp_cOx9Qenb",
        "colab_type": "text"
      },
      "source": [
        "This notebooks tries to solve the CartPole-V1 problem using deep q-learning by using only the observation space\n",
        "\n",
        "[Reference](https://towardsdatascience.com/cartpole-introduction-to-reinforcement-learning-ed0eb5b58288)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2Atpdh53BNB",
        "colab_type": "code",
        "outputId": "dc345532-89b7-401b-87eb-0a359026eb00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# imporing required libraries\n",
        "\n",
        "# -*- coding: utf-8 -*-\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "from collections import deque\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.optimizers import Adam"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lPJswEhLRQKK",
        "colab_type": "text"
      },
      "source": [
        "Rendering the envioronment is  a tricky task in colab. So It is required to install and import following libraries\n",
        "\n",
        "[Reference](https://star-ai.github.io/Rendering-OpenAi-Gym-in-Colaboratory/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_n_I0g_F5mY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# installing required libraries\n",
        "!pip install gym pyvirtualdisplay > /dev/null 2>&1\n",
        "!apt-get install -y xvfb python-opengl ffmpeg > /dev/null 2>&1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gl4O_qnUF8iU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# imporing gym and relevant libraries to render\n",
        "import gym\n",
        "from gym import logger as gymlogger\n",
        "from gym.wrappers import Monitor\n",
        "gymlogger.set_level(40) #error only\n",
        "\n",
        "import os\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import math\n",
        "import glob\n",
        "import io\n",
        "import base64\n",
        "from IPython.display import HTML\n",
        "\n",
        "from IPython import display as ipythondisplay"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UCtQ1b6GKhe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# starting the virtual display\n",
        "from pyvirtualdisplay import Display\n",
        "display = Display(visible=0, size=(1400, 900))\n",
        "display.start()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41Rmw8fZGOVK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Utility functions to enable video recording of gym environment and displaying it\n",
        "To enable video, just do \"env = wrap_env(env)\"\"\n",
        "\"\"\"\n",
        "def show_video():\n",
        "  mp4list = glob.glob('video/*.mp4')\n",
        "  print('no of vedios saved : ', len(mp4list))\n",
        "  if len(mp4list) > 0:\n",
        "    file_size = 0\n",
        "    for mp4file in mp4list:\n",
        "      s = os.path.getsize(mp4file)\n",
        "      if (s > file_size):\n",
        "        file_size = s\n",
        "        mp4 = mp4file\n",
        "    video = io.open(mp4, 'r+b').read()\n",
        "    encoded = base64.b64encode(video)\n",
        "    ipythondisplay.display(HTML(data='''<video alt=\"Cartpole-v1\" controls \n",
        "                style=\"height: 400px;\">\n",
        "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
        "             </video>'''.format(encoded.decode('ascii'))))\n",
        "  else: \n",
        "    print(\"Could not find video\")\n",
        "    \n",
        "\n",
        "def wrap_env(env):\n",
        "  env = Monitor(env, './video', force=True)\n",
        "  return env"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E96Qfg1mSXbA",
        "colab_type": "text"
      },
      "source": [
        "## Creating the AI agent\n",
        "\n",
        "\n",
        "*   **brain :** This part present the brain of AI agent. Simple Keras model is implemented hear\n",
        "*   **remember :** The memory of the agent. This help to train the agent using experiance replay\n",
        "*   **act :** action selection mechanism of the agent. epsilon greedy search method is used\n",
        "*   **get_batch :** selecting mini batch for training \n",
        "*   **learn :** learning using the past experiance\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eoMVBs8bjs_M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DQNAgent():\n",
        "  \n",
        "  def __init__(self, observation_space, action_size, max_memory=2000, gamma = 0.95, epsilon = 0.9, epsilon_min = 0.01,epsilon_decay=0.99,learning_rate=0.0001):\n",
        "\n",
        "    self.observation_space = observation_space\n",
        "    self.action_size = action_size\n",
        "    self.memory = deque(maxlen=max_memory)\n",
        "    self.gamma = gamma    # discount rate\n",
        "    self.epsilon = epsilon # exploration rate\n",
        "    self.epsilon_min = epsilon_min\n",
        "    self.epsilon_decay = epsilon_decay\n",
        "    self.learning_rate = 0.001\n",
        "    self.model = self.brain()\n",
        "\n",
        "  def brain(self):\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Dense(24, input_dim=self.observation_space, activation='relu'))\n",
        "    model.add(Dense(24, activation='relu'))\n",
        "    model.add(Dense(self.action_size, activation='linear'))\n",
        "\n",
        "    model.compile(loss='mse',optimizer=Adam(lr=self.learning_rate))\n",
        "    return model\n",
        "\n",
        "  def remember(self, current_state, action, reward, next_state, done):\n",
        "    self.memory.append((current_state, action, reward, next_state, done))\n",
        "\n",
        "  def act(self, state):\n",
        "    if np.random.rand() <= self.epsilon:\n",
        "        return random.randrange(self.action_size)\n",
        "    act_values = self.model.predict(state)\n",
        "    return np.argmax(act_values[0])  # returns action\n",
        "\n",
        "  def get_batch(self, batch_size = 32):\n",
        "    minibatch = random.sample(self.memory, batch_size)\n",
        "\n",
        "    inputs  = np.zeros((min(len(self.memory), batch_size), self.observation_space))\n",
        "    targets = np.zeros((min(len(self.memory), batch_size), self.action_size))\n",
        "\n",
        "    for i,(current_state, action, reward, next_state, game_over) in enumerate(minibatch):\n",
        "        inputs[i]  = current_state\n",
        "        targets[i] = self.model.predict(current_state)[0]\n",
        "        if game_over:\n",
        "          targets[i,action] = reward\n",
        "        else:\n",
        "          targets[i,action] = (reward + self.gamma * np.amax(self.model.predict(next_state)[0]))\n",
        "    return inputs, targets\n",
        "\n",
        "  def learn(self, batch_size):\n",
        "    inputs, targets = self.get_batch(batch_size)\n",
        "    self.model.train_on_batch(inputs, targets)\n",
        "    if self.epsilon > self.epsilon_min:\n",
        "       self.epsilon *= self.epsilon_decay\n",
        "\n",
        "  def load(self, name):\n",
        "    self.model.load_weights(name)\n",
        "\n",
        "  def save(self, name):\n",
        "    self.model.save_weights(name)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5NPC6ysWtaB",
        "colab_type": "text"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYK8LEgU2mFM",
        "colab_type": "code",
        "outputId": "d87bbabd-64ff-4d85-d77e-3e787c421ee4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1071
        }
      },
      "source": [
        "epochs = 100\n",
        "batch_size = 32\n",
        "max_memory = 10000\n",
        "epsilon_decay = 0.995\n",
        "learning_rate = 0.0005\n",
        "max_time_step =1000\n",
        "\n",
        "\n",
        "env = wrap_env(gym.make('CartPole-v1'))\n",
        "observation_space = env.observation_space.shape[0]\n",
        "action_size = env.action_space.n\n",
        "\n",
        "agent = DQNAgent(observation_space, action_size,max_memory=max_memory,epsilon_decay=epsilon_decay,learning_rate=learning_rate)\n",
        "last_time_step = 0\n",
        "agent.load(\"cartpole-v1-dqn.h5\")\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  current_state = env.reset()\n",
        "  current_state = np.reshape(current_state, [1, observation_space])\n",
        "  game_over = False\n",
        "  time_step = 0\n",
        "  \n",
        "  while ((not game_over) and (time_step <= max_time_step)):\n",
        "    \n",
        "    env.render()\n",
        "    action = agent.act(current_state)\n",
        "    next_state, reward, game_over, _ = env.step(action)\n",
        "    reward = reward if not game_over else -reward\n",
        "    next_state = np.reshape(next_state, [1, observation_space])\n",
        "    agent.remember(current_state, action, reward, next_state, game_over)\n",
        "    current_state = next_state\n",
        "    time_step += 1\n",
        "    \n",
        "    if game_over:\n",
        "        print(\"episode: {}/{}, score: {}, e: {:.2}\"\n",
        "              .format(epoch, epochs, time_step, agent.epsilon))\n",
        "        break\n",
        "        \n",
        "    if len(agent.memory) > batch_size:\n",
        "        agent.learn(batch_size)\n",
        "        \n",
        "  if last_time_step < time_step :\n",
        "    last_time_step = time_step\n",
        "    agent.save(\"cartpole-v1-dqn.h5\")\n",
        "env.close()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "episode: 0/100, score: 29, e: 0.9\n",
            "episode: 1/100, score: 18, e: 0.84\n",
            "episode: 2/100, score: 24, e: 0.75\n",
            "episode: 3/100, score: 9, e: 0.72\n",
            "episode: 4/100, score: 30, e: 0.62\n",
            "episode: 5/100, score: 159, e: 0.28\n",
            "episode: 6/100, score: 179, e: 0.12\n",
            "episode: 7/100, score: 178, e: 0.047\n",
            "episode: 8/100, score: 173, e: 0.02\n",
            "episode: 9/100, score: 255, e: 0.01\n",
            "episode: 10/100, score: 195, e: 0.01\n",
            "episode: 11/100, score: 174, e: 0.01\n",
            "episode: 12/100, score: 190, e: 0.01\n",
            "episode: 13/100, score: 220, e: 0.01\n",
            "episode: 14/100, score: 210, e: 0.01\n",
            "episode: 15/100, score: 158, e: 0.01\n",
            "episode: 16/100, score: 152, e: 0.01\n",
            "episode: 17/100, score: 219, e: 0.01\n",
            "episode: 18/100, score: 177, e: 0.01\n",
            "episode: 19/100, score: 178, e: 0.01\n",
            "episode: 20/100, score: 175, e: 0.01\n",
            "episode: 21/100, score: 148, e: 0.01\n",
            "episode: 22/100, score: 164, e: 0.01\n",
            "episode: 23/100, score: 246, e: 0.01\n",
            "episode: 24/100, score: 268, e: 0.01\n",
            "episode: 25/100, score: 179, e: 0.01\n",
            "episode: 26/100, score: 159, e: 0.01\n",
            "episode: 27/100, score: 289, e: 0.01\n",
            "episode: 28/100, score: 163, e: 0.01\n",
            "episode: 29/100, score: 164, e: 0.01\n",
            "episode: 30/100, score: 189, e: 0.01\n",
            "episode: 31/100, score: 177, e: 0.01\n",
            "episode: 32/100, score: 182, e: 0.01\n",
            "episode: 33/100, score: 157, e: 0.01\n",
            "episode: 34/100, score: 191, e: 0.01\n",
            "episode: 35/100, score: 176, e: 0.01\n",
            "episode: 36/100, score: 161, e: 0.01\n",
            "episode: 37/100, score: 171, e: 0.01\n",
            "episode: 38/100, score: 174, e: 0.01\n",
            "episode: 39/100, score: 192, e: 0.01\n",
            "episode: 40/100, score: 193, e: 0.01\n",
            "episode: 41/100, score: 146, e: 0.01\n",
            "episode: 42/100, score: 196, e: 0.01\n",
            "episode: 43/100, score: 193, e: 0.01\n",
            "episode: 44/100, score: 188, e: 0.01\n",
            "episode: 45/100, score: 186, e: 0.01\n",
            "episode: 46/100, score: 194, e: 0.01\n",
            "episode: 47/100, score: 187, e: 0.01\n",
            "episode: 48/100, score: 229, e: 0.01\n",
            "episode: 49/100, score: 148, e: 0.01\n",
            "episode: 50/100, score: 189, e: 0.01\n",
            "episode: 51/100, score: 159, e: 0.01\n",
            "episode: 52/100, score: 186, e: 0.01\n",
            "episode: 53/100, score: 184, e: 0.01\n",
            "episode: 54/100, score: 186, e: 0.01\n",
            "episode: 55/100, score: 235, e: 0.01\n",
            "episode: 56/100, score: 178, e: 0.01\n",
            "episode: 57/100, score: 204, e: 0.01\n",
            "episode: 58/100, score: 175, e: 0.01\n",
            "episode: 59/100, score: 191, e: 0.01\n",
            "episode: 60/100, score: 237, e: 0.01\n",
            "episode: 61/100, score: 240, e: 0.01\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRtHgKc03KOS",
        "colab_type": "code",
        "outputId": "7427334c-9408-4332-aa73-96f673824453",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438
        }
      },
      "source": [
        "show_video()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "no of vedios saved :  5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<video alt=\"Cartpole-v1\" controls \n",
              "                style=\"height: 400px;\">\n",
              "                <source src=\"data:video/mp4;base64,AAAAIGZ0eXBpc29tAAACAGlzb21pc28yYXZjMW1wNDEAAAAIZnJlZQAAG8BtZGF0AAACrgYF//+q3EXpvebZSLeWLNgg2SPu73gyNjQgLSBjb3JlIDE1MiByMjg1NCBlOWE1OTAzIC0gSC4yNjQvTVBFRy00IEFWQyBjb2RlYyAtIENvcHlsZWZ0IDIwMDMtMjAxNyAtIGh0dHA6Ly93d3cudmlkZW9sYW4ub3JnL3gyNjQuaHRtbCAtIG9wdGlvbnM6IGNhYmFjPTEgcmVmPTMgZGVibG9jaz0xOjA6MCBhbmFseXNlPTB4MzoweDExMyBtZT1oZXggc3VibWU9NyBwc3k9MSBwc3lfcmQ9MS4wMDowLjAwIG1peGVkX3JlZj0xIG1lX3JhbmdlPTE2IGNocm9tYV9tZT0xIHRyZWxsaXM9MSA4eDhkY3Q9MSBjcW09MCBkZWFkem9uZT0yMSwxMSBmYXN0X3Bza2lwPTEgY2hyb21hX3FwX29mZnNldD0tMiB0aHJlYWRzPTMgbG9va2FoZWFkX3RocmVhZHM9MSBzbGljZWRfdGhyZWFkcz0wIG5yPTAgZGVjaW1hdGU9MSBpbnRlcmxhY2VkPTAgYmx1cmF5X2NvbXBhdD0wIGNvbnN0cmFpbmVkX2ludHJhPTAgYmZyYW1lcz0zIGJfcHlyYW1pZD0yIGJfYWRhcHQ9MSBiX2JpYXM9MCBkaXJlY3Q9MSB3ZWlnaHRiPTEgb3Blbl9nb3A9MCB3ZWlnaHRwPTIga2V5aW50PTI1MCBrZXlpbnRfbWluPTI1IHNjZW5lY3V0PTQwIGludHJhX3JlZnJlc2g9MCByY19sb29rYWhlYWQ9NDAgcmM9Y3JmIG1idHJlZT0xIGNyZj0yMy4wIHFjb21wPTAuNjAgcXBtaW49MCBxcG1heD02OSBxcHN0ZXA9NCBpcF9yYXRpbz0xLjQwIGFxPTE6MS4wMACAAAABa2WIhAAz//727L4FNf2f0JcRLMXaSnA+KqSAgHc0wAAAAwAAAwAAFgn0I7DkqgN3QAAAHGAFBCwCPCVC2EhH2OlcHu3+WKSG4ShS6WACkOYpE7jOj6wFkiLJ/Ad0EWHlX9Ttg+uGKGEM0zPD5jEHlvwEFj18wXxhrbvF7t+AJM8eh1EO6k9l3fp9rUNUAeZ8+uIJIFEdMSzwKrhEO6xnBC0yP5hCrowfMpXs9Wdy1wVFH1tQVNxL+e4Wpu6NqCJhrns3BUA912+dsW9Ge914Mxjz7dkd5yUW7oRMFhaGq1FhsaNmXZ06a7eRbf1V1X96D+FNCALFutm2DdkXvP/5T2TYEr4GouM9CNb7sCdf9KLk5MuHCiApb2XkZ22j/u+oyTQglZzp6IklO7CwRukqatuPUE7cqOAcBHCOXTDRNPVflNm4kJBNg43oN6d8fx1+F9Ekm1mGsAwZt10MO7HBW0QAAAMAAAMAAAMBvQAAAJZBmiRsQz/+nhAAAEVJ2FyAK1S3e1ULN6Ai8Al6FjCimH1VPTAGR2lJ67fJxXABHo5zzPGjiIJRbr862ckOdJRv2rriajPnscct1jN0Uw/PqhkF3AtQy8ELnAJknL0lHKpkpcGwwZAqLBuCIS/lCg/3ZHO+eCoS43pGmVkNI2gKWRLfe+0AAPF+1bZ1YtG3AV30wjR8nCQAAAAvQZ5CeIR/AAAWsyyQYfPSWFb9tX0y/dhgXrOCgoOOTDBHpAAAAwAO1Q7rUtiqArcAAAAoAZ5hdEf/AAAjwLnMaWquxgLUnaRd1ZtKK5NIWwAAAwAAAwFqnfCBnwAAACIBnmNqR/8AACO/H4/7JTNTnOxQgbba7lWWhn90jq863AUlAAAAdUGaaEmoQWiZTAhf//6MsAAARgL9IwAsFBB2oxrlVe5Cj68egrXPpGkfARTvFfhsRrf7ndvLX20iXrLGJsIECtg0UAT2FWXHOf5BfVLA8uJNSG4iFw3RJiyQRWE3dwtDes/9JO1Tr1zitj4Q8sCUmc/Sy2Hs7wAAADZBnoZFESwj/wAAFrxOniNGr1rEO7ABM1AIxjqvvwDJ0sJXYEvR1xrsbHUeIvjfy1Zp0ZiAVsEAAAAtAZ6ldEf/AAANgdB5bwUmb/RmcKigTnRk11Ipm/xHRKuBcJgmIDz3iyBdbCI/AAAAOAGep2pH/wAAI53kMFex+RLL+hHFZzrbIb34t+mwvKAA/c0jVBkH/VXLXx4wJzAQ/7iiSVm6+AHrAAAAeEGarEmoQWyZTAhf//6MsAAARiUeQ22h8Wrz4aq4OurdqVINN0aWsEUBgBBxKrIzqhIAK8+Y95Bhz06XFx9ovM7D1hJBd9BllvEyqZyrnnfAbTaZw/xMUyvLn5zbfBJSHCVadmZV85Dr3/B961YhofZ3upZfhApkHAAAAExBnspFFSwj/wAAFrMsA55PPsHSZ1r2qNCT6ujvbyiNsXzGZUqd8j80GwJDYTLPlQ5MFn5s5QCb9W/DMJWKI3gW7a9HwXnhixC/igLLAAAAKgGe6XRH/wAAI8M5qW1vtdM+3NuPQMTcu60xyi+Ddctz8BVjpBVD4gAZ8AAAAC8BnutqR/8AACPHMp7+uTYi/IXDitRx0RdqgNKPEpNKB7gz0prWiYFS3nUfb/wd0AAAAGxBmu5JqEFsmUwUTDP//p4QAABFY+ld/4a8AiiwPMRub8hDDlgDiCbz6jl8rPo7k27hYRAzfgv2m5q0/X+3zGczVPCVfZBQkrABQpDa5jAMOb6n6K+5gUNwzZpieOA3aIDqIbihGyL8FMhpL5sAAAA8AZ8Nakf/AAAjvwQmbs/PM50MiOboXk41AY7326Fjiez9W/d5PQ1tAgoMjHz5gBMaAbl0KIYXBgTox+3zAAAAhUGbEknhClJlMCGf/p4QAABFRJGbABF9nkD3WG6gteh8C1vmhQ9kHn8RKTHksojUjZD4e8h6r1qcS/Mvv5wbdM2MSQzuT7Ux+cHjKQe3em23hfTx0lZDLTPaOAVMt/21ai5Nbpk7SHBD1bwstvu91gDuZ3ZHSQYFmLk9Jo4Uggg2oZbXLlEAAABHQZ8wRTRMI/8AABaoDsW8Ms9HEjayBsi5Mdno2wQuTeJ8m2cTsLceFspDf1DACxgVcnuS59uH3jGcqkilm9YYm6prwBi+osAAAAA0AZ9PdEf/AAAjwxdQeyeNCLCustYUzMMLzu5yJPy75ro19ysWrmMosEWwAPYVxxmGEC4uNAAAADwBn1FqR/8AAA1cYKKnmH4+dZ1xL6QXz0QVCEdPeY4dqgW+lEA4orWUIFHoAPyzMDcqVyEbukxLmRiTUWEAAACjQZtWSahBaJlMCGf//p4QAABFQ23zIAIlTHGadCusMoJQNoW7DMrIQDvWaiTcyZvgSHkl42G+NNI+Z8hpSU6N73i/N8KBvOAg3EzgiCGZNYo+OqR5T1Zi5/8Gjy78ydrobFZTDZHdmI6HAM1dHa82yLJk8aBmlpKSGeS4nsuLy8nF6fdpvGwwlqB3iOlm7ygp4KCTE0/21stglaCemytFEIPFHgAAAEpBn3RFESwj/wAAFruUVLF0+hkY0Ryq+/LRKXeaJNoVpEsNm14LQIdnKosaF9nuNKr80uUbLDACRFWL0ttlIGsueYAR3cY3Zrx14AAAADUBn5N0R/8AACK3x4d2lprvyFJEPWzj+xu9myMD7yMoUjA0gATBPgBzjo/LpBSHBCKbbqUo+QAAADEBn5VqR/8AACO9lgKJd/ntEuyHLEcmDrQhoK9B4gmCrEYAT7slYZEWqEQOx702RAOCAAAAiEGbmkmoQWyZTAhn//6eEAAARbpvQKF6fcfTlvQmJYYiclkTlT1a/dxRuxozu5ukVsx/ddP5WbtLNJiAImbcyMdIeWSvC8+WchQoBJeERjGDSPYx8exrbbcJDd6QvIu+q3S258ByRcZAVvpPfXS1/6+cGmgne+UX8Ws6I76/e/gonhQuUbGPenEAAABMQZ+4RRUsI/8AABayncbzWAUbtFJKnAKY1JKPNPkKwIHnvyxzE47MeFo0yC/YDS5Jw9ZwAWpFO2knsVv0gjvCCyDt9X0+X2AUyT8NmQAAAEMBn9d0R/8AACPAuB66y7oBpFyMjztPmzu1BjVea7Gl04pIBaHYC4tTfQp2Z6AD9b3oDOnSxmXUYdZzqtKRyHCVcPOBAAAANAGf2WpH/wAAI64xL9Iy1HGzhT2wPYnaPdTgo3Pp2sssyuEhh9J5B8bDdSr7hACZGf/17oEAAAB1QZveSahBbJlMCGf//p4QAABDQ9Z3gAcWlTwMf7LC3CeM0Np3De9RWIIje5/7PoAXIkE9Llv08gFqJ/HJiLf+5D1ONYbWLcDrXInWwI8W+HFk6WQyQ+OIqR6VEUrTUNA/46HBvKjAb1SJZPW9XSFzCp6kwvigAAAATkGf/EUVLCP/AAAWIp9fDlGCT1O73N1zgUygmaEI+5H6B6tXpB4xWsYGTxYpH35QT4AH86kmOAgvoe5rT2jCZKuV2zYDYrMOJsjQgcFrZwAAADABnht0R/8AACLAucu3Hxl8vnFIicwg38pdFQxbw6/VuuN18AwBrDoXgd1Z/Rif7kkAAAA8AZ4dakf/AAAirjMLUVXKZDOT6N+63eNQ9DZiYsCANlk7TVtVtki4UJzQAkTu7XmnFFNTgcCJiLZKeCVAAAAAdUGaAkmoQWyZTAhf//6MsAAARAFiGDACw9Tc5G2HAmSH83u/c7x0Si4WL5GK1I7mGZY+v85VL82p/vTCmdY7k9F0mrDPhu+9ipm7ezC+GI3kJV6BsMXxRlkO8CL8wwfaUE3vAh+kq4d9O6WloPIW+u/yQ+qENQAAAFRBniBFFSwj/wAAFhe66oaoaS/2QRkAIyZMgF3iDy2YSwyeD8ShTeQXND5rBs3HJfF4E1LjOigvbXgyozH9Zf8o28zKuCGbOGzVSTPVDfTqDB8CwpMAAAA6AZ5fdEf/AAAiwLj6m/5pjcFXwAhYBiPlsADNHkiFCbtt6z2cyP883xrtHMBz9c3ybZ4t8xPLVI6b8AAAADYBnkFqR/8AACKZpjSpSCiHLvH3xBKUnU6gyYE+SSXy9muDsdhGpTqWMXez4UuceJD0IR3r5UEAAABgQZpGSahBbJlMCF///oywAABEAXWwQ+BoeqCcuQM7+gi2ytH03wgd1FmFE7TzH9Q9+/gHfqqD2TXfFriaXp/ymMxMqjYAaFp803J2yMRYSGpQ46vHXlN1p1gyS2dzG9iAAAAAR0GeZEUVLCP/AAAWKyVMiAsjhZYQy2awM5XeipULTgLHqQ7ebcO36u+dI6W0+0yTEPHZowSr+sPdrIAVzpnemS6iSWqlcnaBAAAAOwGeg3RH/wAAIsAho7qCpEa++TKruwfMuUyFkap7WmxltJd4Andas/ZDDwWl+PP2Y8kVGwase/caiECVAAAAOgGehWpH/wAAIr1YkeCmy4/DgVvhdi1gS0O6wfm4E+rxUj1QixZWT67McKnrVjt1uFdDtWz3YzpqTbEAAABzQZqISahBbJlMFEwz//6eEAAAQ7pvOsiEG+n0VUzoTTINHs1e2TagTnV3abUyH4bKy96eYoAWN4KeaEOgf/MeU+ajf7e5XMDcXgA5wCaP3WcFgXjWjk6Nu6yxE35ym+AZVAtg8OLUDATbqny8zwrU5MdrvQAAAEwBnqdqR/8AACKxv3z9QKhv+XD73tkurE8ehhLOLMukAZsa7egjGEgS6wgABbJWJjZk7pDpcHM6F7egyGR6V+bTn8CKxCPDhrECF5kwAAAAkkGarEnhClJlMCGf/p4QAABBUPhtTyAG41UgNGT8yaave0xdX7rGi0ItV84cypEO6G/+idos6lnjnyhYMJQ/TjmK6inbo+WIglcn+o3WcAxELHEBgLk+B+0g9piu6miB0OKBeYqDtWNe1oFo8mnZ3D8PJZ044MoxEwJfjCOYIsc5kKinN7/ZEblu5DLezNuaG12cAAAAWkGeykU0TCP/AAAVmzaVjyKS5jkW9OswdIBAUEa6oUvo0BrJEfqSsLOxrFbutVMViXzmZg+0NAjQgAF1FI5yo08F9K6F7UWDxKgj/qNdteFR0N/xg+SIGh9UCQAAAEYBnul0R/8AACGpQMWPUgV+QYxI7oH3oZR8ecEH4m7/yg2ENpqBkQyCE77fpUyjnT8gN3qS4DB2bzVaB4XGvr4P2vmkPY7AAAAAOQGe62pH/wAAIZkUG0tqF0SrtGrw7WfYi2L7s4XFS+y79D6W5UVns+ZPO8hReUnYBsQebj2mkj5qsAAAAHZBmvBJqEFomUwIX//+jLAAAEJ6bz3UrxYAC2aKINHUFrYWFoCOYgksUsujhgnRyNiUxx8IzTPVu3tqn6S3YTcmIdgIq7Bgy3izZF3bnPxn9vvdX1qgExUH7g3SOexcDIY+bh4/7rTDkynNDX4oGLAE4boDsKXlAAAARkGfDkURLCP/AAAVoDzNeJGypxOZKpUZFjTIvFhhFKUOyhfkavQGjam3JlAv5kq9kYLWi+XWzgBKkCFAvuOWXDZ/X6NJ29EAAAA4AZ8tdEf/AAAhv/5unTbPaLW7LH8C56oAen7IZ6jYj6yAyP5POBmPI1XciPWLxjumSfkjhyq4JMEAAAA5AZ8vakf/AAAhrUa4qIf8KiiNzxb58ociW4KV7VSfWBZ+bmq0TS4rigflxVBcbRMY6uYBPadtA7ggAAAAdkGbNEmoQWyZTAhf//6MsAAAQBCvYYMALD57H0uueLgsz2V2npliTE7VxXRowuMhpj7tcxllRp7S150TnwdcYaiCDKVva4OaWWjaAVb0E5SfVXbnKmz0y0SqKPr+6TrSHJUeirvOSGbLlNd/MiiyFF6UU4aAhEAAAABBQZ9SRRUsI/8AABUQPtvtPeJh2+dwuoSUhf/R1EwMYamwxby5l1xmZPGiFXPJQi/JLaaxTv7IabYuYl/OOwzm7bUAAABEAZ9xdEf/AAAgqUDUqHXS+DiOJxtUhs5ZT0V7P4QWjZsCbl3BCFqJc7Ilp+0TuvtMd7Muf3ooRMCn1fbQQyNIenweN6MAAAAwAZ9zakf/AAAgq7FlSTZM3WivqYY+1VqPMeQjwKXg0yY7TCaQ6mS7uWk+q73LJ+pgAAAAc0Gbd0moQWyZTAhf//6MsAAAQHptnlZWiTGiP1GD8gH7Hyt/w6KyZgkChcgA3GkckD1T8fDVWuf/t/G4UUDTLlaWVuT3kpZG42WQP9zlD1Ra+3/s+3qzCkCOH6qBKAd9FUTj9pvGVmBtML++mqwGHLKvanEAAAAxQZ+VRRUsI/8AABULJUbGpHtYFSzjIss2HuIeqUQ4CsoisqafLNjFezjK9zVvKIr6mAAAADwBn7ZqR/8AACCxuvB9rQkjWa1i2uRLDJp6rg0Jimgk+aW4R4lAsKXK/gRvjciU8FpPv1B5o1GaA609CBcAAACqQZu7SahBbJlMCF///oywAAA+XMKygU9ABHaZPY0QBQMSWYw33R11/p8yvHhnbhBLSoCuvC4PyMTOamcLfh0lpdaY173nDTMK3UfKVyJXNsAlwMUdxd/jue2+SBRQ/fRJmKOOUuuaYEgLv9vUBFNpIs93pqybhls69pmXJZeFgc3ATpJTWHgDFpKC1HxgkWysT+9AzCENUCbdCtwhV2XZaGlyzvD0SwrxFk0AAABPQZ/ZRRUsI/8AABR7PFULo7ZRwxSPeu+CQV6cvDMk2yf6e2lEz6bVY9fAYypDA4yX7HpFwICXGkDQyOs8Esy+5gBdIwct5AlUp3Wbn/r1YAAAAFEBn/h0R/8AAB+mt9nBvHg9wv+5YhnoirdslTqaq8PuYHlgirQn+SyWWTJY2SBUIUgHwATVpedLMln+oJ5tZHBsvxykHL4nfgsH/5sAzEuoPVkAAABNAZ/6akf/AAAfuAYWfy1JRgoKE0e6KiEVUccBHpf//V3HvQPFPzFLqvEHtUZLPFsR1QM4bIj4KVlJRMuWgED3FLxAALDkDO9Epr1bRWAAAACZQZv+SahBbJlMCF///oywAAA+vrag+boo4wAjC5phtQIJkRLj9t94Ro236+GXuUZmpgB0lGPrqRJOLKxNVZlEg/cdbzpwnDrMWqseAxPZQ3FPhg3g8lc2jhAXZrzeUMV3xA3eKdDMbnQzLEv5FsPwhlIf5oRLIDS7I1857xlrN6AmlOPT97i3fO/GGYoqBob7snK69uF4reOBAAAAYkGeHEUVLCP/AAAUdTbNfMziQgR3XcAOpc6i/8Pru9keLSb/I5torAe++DgBuX+rKzfcKvlrdGCicBzDlHSNv6++fcJkU6zQSMfruhCzQS9NMtUl0dyxXfvao0VK45bORuqbAAAARwGePWpH/wAAHwJIp+LXeYjb0xPt3vS1RWNetEaYshkmMJTIXLFtdyZAdWJZFfuIl34lxsOV8lYygK3iMzrQ4WRPHukWDciBAAAAdEGaIUmoQWyZTAhX//44QAAA7m/889mwYgiscsAItdEsCBdx/qoEyv/YlcWyXgN/yg3jmzKzJXvVtbGGWw9XnLb8bWKAkfxfcwHFgW1dpIKRDoS7+F8UGk8BkCzcrGH23yMOD5yTxi3tpHtMBXSlxh4RjaKSAAAASUGeX0UVLCP/AAAT4lzfNoFCL6fAgree3CpGzxFejsVUt7957yB3tqkbUq4KBiB9wUY2HIyL228MErrkNbFVcLk3IA6gPfK46scAAABEAZ5gakf/AAAfCClV8O6hsy4aJj9N2n0apSMWDFEZKIWNdJ7NT9SlAQwmeNU3uUDACIKY7ZBE8X35X7316cM8i4XoSr0AAACAQZpjSahBbJlMFEwr//44QAAA52OxPLACK6k0kKaNKwxxKpRzwnXeYazqKpU2608JTvQDEgjDVZFmgT/2Jh9QlMa3yrErkNVqwJpjAscqffs85DeuSEzcoAE3ImVH4kY5AoZF9CyMYXmzLI9VSclj+vME69d44YlTj1gH6xKZD48AAABYAZ6Cakf/AAAeRSP4HWsQdCRlB3ItjIYJGIkqUjn3TKoef3EkT9g8hLNdDPzu4pVZGjXeXerlAACcnh0PML5OjxQMXvdj0a+lPCcFzw2he6C31KMlau0fcAAAAHBBmoZJ4QpSZTAj//yEAAAN35Q34fh8IAV/fKRYU0T1x+GxpklBXJgYLjNUBJF7MmeHP0+GkfsBErkmIVI04M+ykTVvOx9ZDbr1uakc9tNybDCGckn4uKjMJk+Wt8EtD6xuJYmwMgMvLPo0ZWgojJsHAAAAZ0GepEU0TCP/AAATYj+haEwA1OpMBf81z57Tr0rKV/RXGW9TrnRWDgySZyUqga++gmdenjvMprj640J9aVfcABBR4nmEAH7+uJdwgRweWFLEnlMzro7u+tMcMbZ35HF4i5T/OIT2qaEAAABSAZ7Fakf/AAAeXG8agu3WAFfd4J8O99GIMGt8naMDIu8qyFZ+En8VuWITGx2ZrFe0LJWWtWsiiXjvDzkpt6LYQHiUazg2ga53r5jweLLS7hNm4QAABkdtb292AAAAbG12aGQAAAAAAAAAAAAAAAAAAAPoAAAFjAABAAABAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACAAAFcXRyYWsAAABcdGtoZAAAAAMAAAAAAAAAAAAAAAEAAAAAAAAFjAAAAAAAAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAEAAAAACWAAAAZAAAAAAACRlZHRzAAAAHGVsc3QAAAAAAAAAAQAABYwAAAIAAAEAAAAABOltZGlhAAAAIG1kaGQAAAAAAAAAAAAAAAAAADIAAABHAFXEAAAAAAAtaGRscgAAAAAAAAAAdmlkZQAAAAAAAAAAAAAAAFZpZGVvSGFuZGxlcgAAAASUbWluZgAAABR2bWhkAAAAAQAAAAAAAAAAAAAAJGRpbmYAAAAcZHJlZgAAAAAAAAABAAAADHVybCAAAAABAAAEVHN0YmwAAACYc3RzZAAAAAAAAAABAAAAiGF2YzEAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAACWAGQAEgAAABIAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY//8AAAAyYXZjQwFkAB//4QAZZ2QAH6zZQJgz5eEAAAMAAQAAAwBkDxgxlgEABmjr48siwAAAABhzdHRzAAAAAAAAAAEAAABHAAABAAAAABRzdHNzAAAAAAAAAAEAAAABAAACKGN0dHMAAAAAAAAAQwAAAAEAAAIAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAAAwAAAAABAAABAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAAAAEAAAMAAAAAAQAAAQAAAAABAAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAAEAAAAAAIAAAEAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAAEAAAAAAIAAAEAAAAAAQAABAAAAAACAAABAAAAAAEAAAMAAAAAAQAAAQAAAAABAAAEAAAAAAIAAAEAAAAAHHN0c2MAAAAAAAAAAQAAAAEAAABHAAAAAQAAATBzdHN6AAAAAAAAAAAAAABHAAAEIQAAAJoAAAAzAAAALAAAACYAAAB5AAAAOgAAADEAAAA8AAAAfAAAAFAAAAAuAAAAMwAAAHAAAABAAAAAiQAAAEsAAAA4AAAAQAAAAKcAAABOAAAAOQAAADUAAACMAAAAUAAAAEcAAAA4AAAAeQAAAFIAAAA0AAAAQAAAAHkAAABYAAAAPgAAADoAAABkAAAASwAAAD8AAAA+AAAAdwAAAFAAAACWAAAAXgAAAEoAAAA9AAAAegAAAEoAAAA8AAAAPQAAAHoAAABFAAAASAAAADQAAAB3AAAANQAAAEAAAACuAAAAUwAAAFUAAABRAAAAnQAAAGYAAABLAAAAeAAAAE0AAABIAAAAhAAAAFwAAAB0AAAAawAAAFYAAAAUc3RjbwAAAAAAAAABAAAAMAAAAGJ1ZHRhAAAAWm1ldGEAAAAAAAAAIWhkbHIAAAAAAAAAAG1kaXJhcHBsAAAAAAAAAAAAAAAALWlsc3QAAAAlqXRvbwAAAB1kYXRhAAAAAQAAAABMYXZmNTcuODMuMTAw\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "andzTupPLkwn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}